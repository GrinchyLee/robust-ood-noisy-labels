{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZ3_c6oHkfsb"
   },
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import torch\n",
    "import pickle\n",
    "from openood.evaluation_api import Evaluator\n",
    "from openood.networks import ResNet18_32x32\n",
    "from openood.networks.lenet import LeNet # just a wrapper around the ResNet\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로\n",
    "file_path = \".pth.tar\"\n",
    "\n",
    "# 모델 정의\n",
    "net = ResNet18_32x32(num_classes=10)\n",
    "\n",
    "# 저장된 모델 로드\n",
    "checkpoint = torch.load(file_path, map_location=torch.device(\"cuda\"))  # CPU에서도 로드 가능하도록 설정\n",
    "\n",
    "# 'module.' 키 제거 (DataParallel에서 저장된 경우)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint.items():\n",
    "    new_key = k.replace(\"module.\", \"\")  # 'module.' 접두사 제거\n",
    "    new_state_dict[new_key] = v\n",
    "\n",
    "# 모델 가중치 로드\n",
    "net.load_state_dict(new_state_dict)\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "net.cuda()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOD_list = ['msp', 'odin','ebo','gradnorm','react','mls','klm','vim','knn','dice','rankfeat','ash','she','mds','rmds','gram','mds_ensemble','temp_scaling','openmax']\n",
    "\n",
    "\n",
    "res = []\n",
    "for method in OOD_list:\n",
    "    print(f\"-------------------{method}----------------------\")\n",
    "    postprocessor_name = method\n",
    "    evaluator = Evaluator(\n",
    "        net,\n",
    "        id_name='cifar10',                     # the target ID dataset\n",
    "        data_root='./data',                    # change if necessary\n",
    "        config_root=None,                      # see notes above\n",
    "        preprocessor=None,                     # default preprocessing for the target ID dataset\n",
    "        postprocessor_name=postprocessor_name, # the postprocessor to use\n",
    "        postprocessor=None,                    # if you want to use your own postprocessor\n",
    "        batch_size=200,                        # for certain methods the results can be slightly affected by batch size\n",
    "        shuffle=False,\n",
    "        num_workers=2)                         # could use more num_workers outside colab\n",
    "    \n",
    "    metrics = evaluator.eval_ood(fsood=False)\n",
    "    near,far = metrics['AUROC']['nearood'],metrics['AUROC']['farood']\n",
    "    accuracy = metrics['ACC']['nearood']\n",
    "\n",
    "    res_each = [method,near,far]\n",
    "    res.append(res_each)\n",
    "\n",
    "res.append(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# 지정된 파일 경로\n",
    "file_path = '.pkl'\n",
    "\n",
    "# res 리스트를 pickle 파일로 저장\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(res, f)\n",
    "\n",
    "print(f\"Results have been saved to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
